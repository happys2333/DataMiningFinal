{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "GPU = 0\n",
    "device = torch.device(\"cuda:{}\".format(GPU)) if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Param list\n",
    "EPOCH = 300\n",
    "TIMESTEP = 12\n",
    "TRAINDAYS = 30\n",
    "\n",
    "OPTIMIZER = 'Adam'\n",
    "LEARN = 0.0001\n",
    "PATIENCE = 20\n",
    "beijing = None\n",
    "changchun = None\n",
    "shenzhen = None\n",
    "shanghai = None\n",
    "Loss = nn.L1Loss()\n",
    "scaler_dict = dict()\n",
    "model_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def csv_to_tensor(file):\n",
    "    Data = pd.read_csv(file)\n",
    "    scaler = StandardScaler()\n",
    "    scaler_dict[file.split('/')[2][0:-9]] = scaler\n",
    "    f = Data['confirmedNum'].to_numpy()[::-1].reshape(42, 1).astype(float)\n",
    "    f = scaler.fit_transform(f)\n",
    "    x_data = np.arange(0, 42, 1)\n",
    "    x_data = x_data.reshape(-1, 1).astype(int)\n",
    "    data = np.append(x_data, values=f, axis=1)\n",
    "    d = torch.from_numpy(data.copy())\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_csv_to_list():\n",
    "    global beijing\n",
    "    global shenzhen\n",
    "    global changchun\n",
    "    global shanghai\n",
    "    beijing = csv_to_tensor('./input/beijing_data.csv')\n",
    "    shenzhen = csv_to_tensor('./input/shenzhen_data.csv')\n",
    "    changchun = csv_to_tensor('./input/changchun_data.csv')\n",
    "    shanghai = csv_to_tensor('./input/shanghai_data.csv')\n",
    "\n",
    "\n",
    "read_csv_to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -1.3168e+00],\n",
       "        [ 1.0000e+00, -1.2994e+00],\n",
       "        [ 2.0000e+00, -1.2835e+00],\n",
       "        [ 3.0000e+00, -1.2739e+00],\n",
       "        [ 4.0000e+00, -1.2517e+00],\n",
       "        [ 5.0000e+00, -1.2184e+00],\n",
       "        [ 6.0000e+00, -1.1961e+00],\n",
       "        [ 7.0000e+00, -1.1739e+00],\n",
       "        [ 8.0000e+00, -1.1358e+00],\n",
       "        [ 9.0000e+00, -1.0913e+00],\n",
       "        [ 1.0000e+01, -1.0532e+00],\n",
       "        [ 1.1000e+01, -9.9766e-01],\n",
       "        [ 1.2000e+01, -9.4685e-01],\n",
       "        [ 1.3000e+01, -8.4999e-01],\n",
       "        [ 1.4000e+01, -7.7060e-01],\n",
       "        [ 1.5000e+01, -6.4198e-01],\n",
       "        [ 1.6000e+01, -5.4671e-01],\n",
       "        [ 1.7000e+01, -3.5935e-01],\n",
       "        [ 1.8000e+01, -2.2438e-01],\n",
       "        [ 1.9000e+01, -1.0211e-01],\n",
       "        [ 2.0000e+01, -1.7958e-02],\n",
       "        [ 2.1000e+01,  6.1435e-02],\n",
       "        [ 2.2000e+01,  1.1066e-01],\n",
       "        [ 2.3000e+01,  1.6782e-01],\n",
       "        [ 2.4000e+01,  2.3927e-01],\n",
       "        [ 2.5000e+01,  3.1549e-01],\n",
       "        [ 2.6000e+01,  4.3775e-01],\n",
       "        [ 2.7000e+01,  5.9813e-01],\n",
       "        [ 2.8000e+01,  6.8387e-01],\n",
       "        [ 2.9000e+01,  7.9343e-01],\n",
       "        [ 3.0000e+01,  9.2522e-01],\n",
       "        [ 3.1000e+01,  1.0475e+00],\n",
       "        [ 3.2000e+01,  1.1364e+00],\n",
       "        [ 3.3000e+01,  1.2460e+00],\n",
       "        [ 3.4000e+01,  1.3031e+00],\n",
       "        [ 3.5000e+01,  1.3412e+00],\n",
       "        [ 3.6000e+01,  1.3666e+00],\n",
       "        [ 3.7000e+01,  1.3809e+00],\n",
       "        [ 3.8000e+01,  1.3921e+00],\n",
       "        [ 3.9000e+01,  1.3984e+00],\n",
       "        [ 4.0000e+01,  1.4016e+00],\n",
       "        [ 4.1000e+01,  1.4048e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shenzhen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CausalConv1d(torch.nn.Conv1d):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True):\n",
    "        super(CausalConv1d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "\n",
    "        self.__padding = (kernel_size - 1) * dilation\n",
    "\n",
    "    def forward(self, input):\n",
    "        return super(CausalConv1d, self).forward(F.pad(input, (self.__padding, 0)))\n",
    "\n",
    "\n",
    "class context_embedding(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1, embedding_size=256, k=5):\n",
    "        super(context_embedding, self).__init__()\n",
    "        self.causal_convolution = CausalConv1d(in_channels, embedding_size, kernel_size=k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.causal_convolution(x)\n",
    "        return torch.tanh(x)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, device=device, dmodel=256):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.input_embedding = context_embedding(2, dmodel, 9)\n",
    "        self.positional_embedding = torch.nn.Embedding(TIMESTEP, dmodel)\n",
    "        self.device = device\n",
    "        self.dmodel = dmodel\n",
    "        self.decode_layer = torch.nn.TransformerEncoderLayer(d_model=dmodel, nhead=4)\n",
    "        self.transformer_decoder = torch.nn.TransformerEncoder(self.decode_layer, num_layers=6)\n",
    "        self.fc1 = torch.nn.Linear(dmodel, int(dmodel / 2))\n",
    "        self.fc12 = torch.nn.Linear(int(dmodel / 2), 1)\n",
    "        self.fc2 = torch.nn.Linear(TIMESTEP, 1)\n",
    "\n",
    "    def forward(self, x, y, attention_mask):\n",
    "        z = torch.cat((y.unsqueeze(1), x.unsqueeze(1)), 1)\n",
    "        z_embedding = self.input_embedding(z).permute(2, 0, 1)\n",
    "        positional_embeddings = self.positional_embedding(torch.arange(0, TIMESTEP).to(self.device)).expand(1, TIMESTEP,\n",
    "                                                                                                            self.dmodel).permute(\n",
    "            1, 0, 2)\n",
    "        input_embedding = z_embedding + positional_embeddings\n",
    "        transformer_embedding = self.transformer_decoder(input_embedding, attention_mask)\n",
    "\n",
    "        output = self.fc1(transformer_embedding.permute(1, 0, 2))\n",
    "        output = self.fc12(output).permute(2, 0, 1)\n",
    "        output = self.fc2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, name,test):\n",
    "    model.eval()\n",
    "    l_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, TIMESTEP):\n",
    "            x = test[i + TRAINDAYS - TIMESTEP: i + TRAINDAYS, 0].reshape(1, -1).float()\n",
    "            y = test[i + TRAINDAYS - TIMESTEP: i + TRAINDAYS, 1].reshape(1, -1).float()\n",
    "            attention_mask = torch.from_numpy(np.zeros((TIMESTEP, TIMESTEP)))\n",
    "            y_pred = model(x.cuda(), y.cuda(), attention_mask.cuda())[0][0][0]\n",
    "            # y_pred = model(x.cuda())[0][0]\n",
    "            loss = Loss(y_pred.float(), test[i + TRAINDAYS][1].cuda().float())\n",
    "            l_sum += loss.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "        return l_sum / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, name, data):\n",
    "\n",
    "    print('Model Training Started ...', time.ctime())\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARN)\n",
    "    min_val_loss = np.inf\n",
    "    for epoch in range(EPOCH):\n",
    "        starttime = datetime.now()\n",
    "        model.train()\n",
    "        loss_sum, n = 0.0, 0\n",
    "        for i in range(0, TRAINDAYS - TIMESTEP):\n",
    "            optimizer.zero_grad()\n",
    "            x = data[i:i + TIMESTEP, 0].reshape(1, -1).float()\n",
    "            y = data[i:i + TIMESTEP, 1].reshape(1, -1).float()\n",
    "            attention_mask = torch.from_numpy(np.zeros((TIMESTEP, TIMESTEP)))\n",
    "            y_pred = model(x.cuda(), y.cuda(), attention_mask.cuda())[0][0][0]\n",
    "            y = data[i + TIMESTEP][1]\n",
    "            loss = Loss(y_pred.float(), y.cuda().float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "            n += 1\n",
    "        train_loss = loss_sum / n\n",
    "        val_loss = evaluate_epoch(model,name, data)\n",
    "        if val_loss < min_val_loss:\n",
    "            wait = 0\n",
    "            min_val_loss = val_loss\n",
    "            open('./model/' + name + '.pt', 'a')\n",
    "            torch.save(model.state_dict(), './model/' + name + '.pt')\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait == PATIENCE:\n",
    "                print('Early stopping at epoch: %d' % epoch)\n",
    "                break\n",
    "        endtime = datetime.now()\n",
    "        epoch_time = (endtime - starttime).seconds\n",
    "        print(\"epoch\", epoch, \"time used:\", epoch_time, \" seconds \", \"train loss:\", train_loss, \"validation loss:\",\n",
    "              val_loss)\n",
    "    print('Model Training Ended ...', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import Metrics\n",
    "\n",
    "\n",
    "def test_model(model, name, data):\n",
    "    loss = nn.L1Loss()\n",
    "    print('Model Testing Started ...', time.ctime())\n",
    "    model.load_state_dict(torch.load('./model/' + name + '.pt'))\n",
    "    YS = data[30:42, 1]\n",
    "    YS_pred = []\n",
    "    scaler = scaler_dict[name]\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, TIMESTEP):\n",
    "            x = data[i + TRAINDAYS - TIMESTEP: i + TRAINDAYS, 0].reshape(1, -1).float()\n",
    "            y = data[i + TRAINDAYS - TIMESTEP: i + TRAINDAYS, 1].reshape(1, -1).float()\n",
    "            attention_mask = torch.from_numpy(np.zeros((TIMESTEP, TIMESTEP)))\n",
    "            y_pred = model(x.cuda(), y.cuda(), attention_mask.cuda())[0][0][0]\n",
    "            YS_pred.append(y_pred.cpu())\n",
    "    YS_pred = np.array(YS_pred)\n",
    "    YS = scaler.inverse_transform(YS.reshape(-1,1))\n",
    "    YS_pred = scaler.inverse_transform(YS_pred.reshape(-1,1))\n",
    "    Mae = 0\n",
    "    for i in range(TIMESTEP):\n",
    "        MSE, RMSE, MAE, MAPE = Metrics.evaluate(YS[i], YS_pred[i])\n",
    "        Mae += MAE\n",
    "        print(\"%d step, %s, %s, MSE, RMSE, MAE, MAPE, %.10f, %.10f, %.10f, %.10f\" % (\n",
    "            i + 1, name, 'Transformer', MSE, RMSE, MAE, MAPE))\n",
    "    print(\"Average MAE Loss is %.10f\" % (Mae/TIMESTEP))\n",
    "    print('Model Testing Ended ...', time.ctime())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Started ... Mon May 23 02:33:18 2022\n",
      "epoch 0 time used: 3  seconds  train loss: 0.2605787383185493 validation loss: 0.7255209485689799\n",
      "epoch 1 time used: 0  seconds  train loss: 0.6748033124539587 validation loss: 0.9631207883358002\n",
      "epoch 2 time used: 0  seconds  train loss: 0.5187350780599647 validation loss: 1.1635419676701229\n",
      "epoch 3 time used: 0  seconds  train loss: 0.46484264276093906 validation loss: 1.186877816915512\n",
      "epoch 4 time used: 0  seconds  train loss: 0.4424713109102514 validation loss: 1.1791003147761028\n",
      "epoch 5 time used: 0  seconds  train loss: 0.459691612670819 validation loss: 1.1734035809834797\n",
      "epoch 6 time used: 0  seconds  train loss: 0.46485449249545735 validation loss: 1.2082143028577168\n",
      "epoch 7 time used: 0  seconds  train loss: 0.4524774248194363 validation loss: 1.2047715733448665\n",
      "epoch 8 time used: 0  seconds  train loss: 0.4550346868733565 validation loss: 1.2004384547472\n",
      "epoch 9 time used: 0  seconds  train loss: 0.42198105063289404 validation loss: 0.9974269072214762\n",
      "epoch 10 time used: 0  seconds  train loss: 0.30541103498803246 validation loss: 0.52285768588384\n",
      "epoch 11 time used: 0  seconds  train loss: 0.2855413522985246 validation loss: 0.768969456354777\n",
      "epoch 12 time used: 0  seconds  train loss: 0.34453168014685315 validation loss: 1.1799346109231312\n",
      "epoch 13 time used: 0  seconds  train loss: 0.40067019448098207 validation loss: 1.0825306574503581\n",
      "epoch 14 time used: 0  seconds  train loss: 0.17108011494080225 validation loss: 0.10406420131524403\n",
      "epoch 15 time used: 0  seconds  train loss: 0.31788084904352826 validation loss: 1.0454765260219574\n",
      "epoch 16 time used: 0  seconds  train loss: 0.40458404355578953 validation loss: 0.917960966626803\n",
      "epoch 17 time used: 0  seconds  train loss: 0.34756919244925183 validation loss: 0.419929638504982\n",
      "epoch 18 time used: 0  seconds  train loss: 0.15304422792461184 validation loss: 0.9220298528671265\n",
      "epoch 19 time used: 0  seconds  train loss: 0.2958844697309865 validation loss: 0.7427151302496592\n",
      "epoch 20 time used: 0  seconds  train loss: 0.2649539224803448 validation loss: 0.5719534258047739\n",
      "epoch 21 time used: 0  seconds  train loss: 0.25764574234684307 validation loss: 0.7509654661019644\n",
      "epoch 22 time used: 0  seconds  train loss: 0.1741300192144182 validation loss: 0.38983216881752014\n",
      "epoch 23 time used: 0  seconds  train loss: 0.24702512390083736 validation loss: 0.3943057755629222\n",
      "epoch 24 time used: 0  seconds  train loss: 0.1417615641322401 validation loss: 0.830986887216568\n",
      "epoch 25 time used: 0  seconds  train loss: 0.2477013940612475 validation loss: 0.4259486347436905\n",
      "epoch 26 time used: 0  seconds  train loss: 0.35732611682679916 validation loss: 0.8030504385630289\n",
      "epoch 27 time used: 0  seconds  train loss: 0.20979729957050747 validation loss: 1.0512489626804988\n",
      "epoch 28 time used: 0  seconds  train loss: 0.4164588736991088 validation loss: 1.0223393440246582\n",
      "epoch 29 time used: 0  seconds  train loss: 0.3308170942796601 validation loss: 0.9139979730049769\n",
      "epoch 30 time used: 0  seconds  train loss: 0.17818978759977552 validation loss: 0.6946708957354227\n",
      "epoch 31 time used: 0  seconds  train loss: 0.11767839681771067 validation loss: 0.4446061948935191\n",
      "epoch 32 time used: 0  seconds  train loss: 0.20910532317227787 validation loss: 0.9299533118804296\n",
      "epoch 33 time used: 0  seconds  train loss: 0.2852655239403248 validation loss: 0.7756285468737284\n",
      "Early stopping at epoch: 34\n",
      "Model Training Ended ... Mon May 23 02:33:41 2022\n"
     ]
    }
   ],
   "source": [
    "# train every city\n",
    "model = Transformer().cuda(device=device)\n",
    "model_dict['shenzhen'] = model\n",
    "train(model,'shenzhen',shenzhen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Started ... Mon May 23 02:33:41 2022\n",
      "epoch 0 time used: 0  seconds  train loss: 0.22725348878237936 validation loss: 0.33172592520713806\n",
      "epoch 1 time used: 0  seconds  train loss: 0.9830518133110471 validation loss: 1.179468368490537\n",
      "epoch 2 time used: 0  seconds  train loss: 0.6465969946649339 validation loss: 1.3109981268644333\n",
      "epoch 3 time used: 0  seconds  train loss: 0.6026915903720591 validation loss: 1.282351404428482\n",
      "epoch 4 time used: 0  seconds  train loss: 0.6046084687113762 validation loss: 1.2708813548088074\n",
      "epoch 5 time used: 0  seconds  train loss: 0.5961640073607365 validation loss: 1.2510628700256348\n",
      "epoch 6 time used: 0  seconds  train loss: 0.5920422017160389 validation loss: 1.2429760893185933\n",
      "epoch 7 time used: 0  seconds  train loss: 0.6185108640541633 validation loss: 1.3386391699314117\n",
      "epoch 8 time used: 0  seconds  train loss: 0.5671452490819825 validation loss: 1.2560378462076187\n",
      "epoch 9 time used: 0  seconds  train loss: 0.5533341216958232 validation loss: 1.1347847481568654\n",
      "epoch 10 time used: 0  seconds  train loss: 0.5914705108023353 validation loss: 0.9522276272376379\n",
      "epoch 11 time used: 0  seconds  train loss: 0.4022398557927873 validation loss: 0.27049314975738525\n",
      "epoch 12 time used: 0  seconds  train loss: 0.8860715611113442 validation loss: 1.3053797880808513\n",
      "epoch 13 time used: 0  seconds  train loss: 0.2755695788396729 validation loss: 0.2233332097530365\n",
      "epoch 14 time used: 0  seconds  train loss: 0.42801884147855973 validation loss: 0.9612553517023722\n",
      "epoch 15 time used: 0  seconds  train loss: 0.4895682864718967 validation loss: 0.9746364653110504\n",
      "epoch 16 time used: 0  seconds  train loss: 0.64769782539871 validation loss: 1.0991277595361073\n",
      "epoch 17 time used: 0  seconds  train loss: 0.6057885400950909 validation loss: 1.228513126571973\n",
      "epoch 18 time used: 0  seconds  train loss: 0.520176388323307 validation loss: 1.0465086897214253\n",
      "epoch 19 time used: 0  seconds  train loss: 0.3024248273836242 validation loss: 0.6398543765147527\n",
      "epoch 20 time used: 0  seconds  train loss: 0.4086628473467297 validation loss: 0.8325648158788681\n",
      "epoch 21 time used: 0  seconds  train loss: 0.39056710836788017 validation loss: 1.247288132707278\n",
      "epoch 22 time used: 0  seconds  train loss: 0.24991840600139564 validation loss: 0.7984134207169215\n",
      "epoch 23 time used: 0  seconds  train loss: 0.19299268598357835 validation loss: 0.20041894912719727\n",
      "epoch 24 time used: 0  seconds  train loss: 0.10831370618608263 validation loss: 0.3307084192832311\n",
      "epoch 25 time used: 0  seconds  train loss: 0.416510430475076 validation loss: 0.9558633317550024\n",
      "epoch 26 time used: 0  seconds  train loss: 0.4010013888279597 validation loss: 0.9450399974981943\n",
      "epoch 27 time used: 0  seconds  train loss: 0.586482553018464 validation loss: 0.814638485511144\n",
      "epoch 28 time used: 0  seconds  train loss: 0.15670699584815237 validation loss: 0.5737482955058416\n",
      "epoch 29 time used: 0  seconds  train loss: 0.21843407510055435 validation loss: 0.36933040122191113\n",
      "epoch 30 time used: 0  seconds  train loss: 0.3515252189503776 validation loss: 0.10934204856554668\n",
      "epoch 31 time used: 0  seconds  train loss: 0.1744607591794597 validation loss: 0.18563982347647348\n",
      "epoch 32 time used: 0  seconds  train loss: 0.49269406166341567 validation loss: 0.8573286483685175\n",
      "epoch 33 time used: 0  seconds  train loss: 0.5923223810063468 validation loss: 1.0118569085995357\n",
      "epoch 34 time used: 0  seconds  train loss: 0.5869629196822643 validation loss: 0.9359516253074011\n",
      "epoch 35 time used: 0  seconds  train loss: 0.4318185483829843 validation loss: 0.09515310327212016\n",
      "epoch 36 time used: 0  seconds  train loss: 0.38896308259831536 validation loss: 0.42481668293476105\n",
      "epoch 37 time used: 0  seconds  train loss: 0.15060853668385082 validation loss: 0.544457733631134\n",
      "epoch 38 time used: 0  seconds  train loss: 0.3424462957514657 validation loss: 0.0449775755405426\n",
      "epoch 39 time used: 0  seconds  train loss: 0.31887650820944047 validation loss: 0.5222103893756866\n",
      "epoch 40 time used: 0  seconds  train loss: 0.46243502882619697 validation loss: 0.9591705898443857\n",
      "epoch 41 time used: 0  seconds  train loss: 0.21511861433585486 validation loss: 0.26042089859644574\n",
      "epoch 42 time used: 0  seconds  train loss: 0.449937179684639 validation loss: 1.2600117077430089\n",
      "epoch 43 time used: 0  seconds  train loss: 0.4297514698571629 validation loss: 0.9225239604711533\n",
      "epoch 44 time used: 0  seconds  train loss: 0.1093725266142024 validation loss: 0.6106223811705908\n",
      "epoch 45 time used: 0  seconds  train loss: 0.3031594217237499 validation loss: 0.5251884410778681\n",
      "epoch 46 time used: 0  seconds  train loss: 0.35754332774215275 validation loss: 0.17085265616575876\n",
      "epoch 47 time used: 0  seconds  train loss: 0.3686239454481337 validation loss: 0.20743528008460999\n",
      "epoch 48 time used: 0  seconds  train loss: 0.08471481212311321 validation loss: 0.36362627645333606\n",
      "epoch 49 time used: 0  seconds  train loss: 0.38543598767783904 validation loss: 0.3624649792909622\n",
      "epoch 50 time used: 0  seconds  train loss: 0.2830166651142968 validation loss: 0.9473718951145808\n",
      "epoch 51 time used: 0  seconds  train loss: 0.42454674281179905 validation loss: 0.5478377168377241\n",
      "epoch 52 time used: 0  seconds  train loss: 0.31690602749586105 validation loss: 0.09012500941753387\n",
      "epoch 53 time used: 0  seconds  train loss: 0.35303443670272827 validation loss: 0.3570331831773122\n",
      "epoch 54 time used: 0  seconds  train loss: 0.18940254714753893 validation loss: 0.3114298035701116\n",
      "epoch 55 time used: 0  seconds  train loss: 0.413194982541932 validation loss: 0.12358440458774567\n",
      "epoch 56 time used: 0  seconds  train loss: 0.21296440892749363 validation loss: 0.5591404289007187\n",
      "epoch 57 time used: 0  seconds  train loss: 0.1930015277531412 validation loss: 0.7316020528475443\n",
      "Early stopping at epoch: 58\n",
      "Model Training Ended ... Mon May 23 02:34:15 2022\n"
     ]
    }
   ],
   "source": [
    "model = Transformer().cuda(device=device)\n",
    "model_dict['shanghai'] = model\n",
    "train(model,'shanghai',shanghai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Started ... Mon May 23 02:34:15 2022\n",
      "epoch 0 time used: 0  seconds  train loss: 0.43305765754646725 validation loss: 1.5917422870794933\n",
      "epoch 1 time used: 0  seconds  train loss: 0.5002476531598303 validation loss: 1.5987942516803741\n",
      "epoch 2 time used: 0  seconds  train loss: 0.4968881706396739 validation loss: 1.6185342172781627\n",
      "epoch 3 time used: 0  seconds  train loss: 0.48348354051510495 validation loss: 1.6322675347328186\n",
      "epoch 4 time used: 0  seconds  train loss: 0.4791332433621089 validation loss: 1.6422257622083027\n",
      "epoch 5 time used: 0  seconds  train loss: 0.49308429741197163 validation loss: 1.6606476604938507\n",
      "epoch 6 time used: 0  seconds  train loss: 0.4838179623087247 validation loss: 1.636814723412196\n",
      "epoch 7 time used: 0  seconds  train loss: 0.4595336682266659 validation loss: 1.4598620235919952\n",
      "epoch 8 time used: 0  seconds  train loss: 0.39715105295181274 validation loss: 0.3251331200202306\n",
      "epoch 9 time used: 0  seconds  train loss: 0.524996693763468 validation loss: 1.584028532107671\n",
      "epoch 10 time used: 0  seconds  train loss: 0.4830265815059344 validation loss: 1.5980618298053741\n",
      "epoch 11 time used: 0  seconds  train loss: 0.45033066471417743 validation loss: 1.5320737659931183\n",
      "epoch 12 time used: 0  seconds  train loss: 0.27782244483629864 validation loss: 1.3881467084089916\n",
      "epoch 13 time used: 0  seconds  train loss: 0.13652309361431333 validation loss: 0.30178140103816986\n",
      "epoch 14 time used: 0  seconds  train loss: 0.2590033519599173 validation loss: 0.3330288877089818\n",
      "epoch 15 time used: 0  seconds  train loss: 0.3295998267001576 validation loss: 1.4805695911248524\n",
      "epoch 16 time used: 0  seconds  train loss: 0.3959561023447249 validation loss: 1.3098516811927159\n",
      "epoch 17 time used: 0  seconds  train loss: 0.16902154104577172 validation loss: 0.856923888127009\n",
      "epoch 18 time used: 0  seconds  train loss: 0.3066014846165975 validation loss: 0.6041043202082316\n",
      "epoch 19 time used: 0  seconds  train loss: 0.21842359917031395 validation loss: 0.569644163052241\n",
      "epoch 20 time used: 0  seconds  train loss: 0.1660802803105778 validation loss: 0.3719899406035741\n",
      "epoch 21 time used: 0  seconds  train loss: 0.2601976924472385 validation loss: 1.0921079168717067\n",
      "epoch 22 time used: 0  seconds  train loss: 0.1912970087594456 validation loss: 0.5210233132044474\n",
      "epoch 23 time used: 0  seconds  train loss: 0.31965358803669613 validation loss: 1.3267309566338856\n",
      "epoch 24 time used: 0  seconds  train loss: 0.312906161778503 validation loss: 0.8961233745018641\n",
      "epoch 25 time used: 0  seconds  train loss: 0.33897355447212857 validation loss: 0.8217872977256775\n",
      "epoch 26 time used: 0  seconds  train loss: 0.2034669475009044 validation loss: 0.5546667029460272\n",
      "epoch 27 time used: 0  seconds  train loss: 0.36836192860371536 validation loss: 0.9320166632533073\n",
      "epoch 28 time used: 0  seconds  train loss: 0.13750224063793817 validation loss: 0.4848683128754298\n",
      "epoch 29 time used: 0  seconds  train loss: 0.18417178591092428 validation loss: 0.2221940557161967\n",
      "epoch 30 time used: 0  seconds  train loss: 0.4442236059241825 validation loss: 1.620926211277644\n",
      "epoch 31 time used: 0  seconds  train loss: 0.4793345895078447 validation loss: 1.6166582604249318\n",
      "epoch 32 time used: 0  seconds  train loss: 0.48379913220802945 validation loss: 1.6179676353931427\n",
      "epoch 33 time used: 0  seconds  train loss: 0.48730206737915677 validation loss: 1.6179223656654358\n",
      "epoch 34 time used: 0  seconds  train loss: 0.47358259310324985 validation loss: 1.6168633500734966\n",
      "epoch 35 time used: 0  seconds  train loss: 0.5017956503563457 validation loss: 1.617207020521164\n",
      "epoch 36 time used: 0  seconds  train loss: 0.5004915578497781 validation loss: 1.61649685104688\n",
      "epoch 37 time used: 0  seconds  train loss: 0.4730086508724425 validation loss: 1.6153811514377594\n",
      "epoch 38 time used: 0  seconds  train loss: 0.48218800458643174 validation loss: 1.6142738958199818\n",
      "epoch 39 time used: 0  seconds  train loss: 0.47185178680552375 validation loss: 1.6125274300575256\n",
      "epoch 40 time used: 0  seconds  train loss: 0.4817180310686429 validation loss: 1.6071742574373882\n",
      "epoch 41 time used: 0  seconds  train loss: 0.4637363188796573 validation loss: 1.5959844887256622\n",
      "epoch 42 time used: 0  seconds  train loss: 0.48579724464151597 validation loss: 1.5765510896841686\n",
      "epoch 43 time used: 0  seconds  train loss: 0.4477500973476304 validation loss: 1.5352989335854847\n",
      "epoch 44 time used: 0  seconds  train loss: 0.42326132042540443 validation loss: 1.3517281015714009\n",
      "epoch 45 time used: 0  seconds  train loss: 0.26661203387710786 validation loss: 0.5005952715873718\n",
      "epoch 46 time used: 0  seconds  train loss: 0.16574332945876652 validation loss: 0.9820178573330244\n",
      "epoch 47 time used: 0  seconds  train loss: 0.1218203314476543 validation loss: 0.40645473698774975\n",
      "epoch 48 time used: 0  seconds  train loss: 0.2386725371082624 validation loss: 0.9822309215863546\n",
      "Early stopping at epoch: 49\n",
      "Model Training Ended ... Mon May 23 02:34:44 2022\n"
     ]
    }
   ],
   "source": [
    "model = Transformer().cuda(device=device)\n",
    "model_dict['beijing'] = model\n",
    "train(model,'beijing',beijing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Started ... Mon May 23 02:34:44 2022\n",
      "epoch 0 time used: 0  seconds  train loss: 0.4417699740992652 validation loss: 0.6413323481877645\n",
      "epoch 1 time used: 0  seconds  train loss: 0.47894033210145104 validation loss: 0.6167537321647009\n",
      "epoch 2 time used: 0  seconds  train loss: 0.475407434006532 validation loss: 0.6312257250150045\n",
      "epoch 3 time used: 0  seconds  train loss: 0.47777266717619365 validation loss: 0.6357981363932291\n",
      "epoch 4 time used: 0  seconds  train loss: 0.46385550250609714 validation loss: 0.637995312611262\n",
      "epoch 5 time used: 0  seconds  train loss: 0.45982586923572755 validation loss: 0.6385976523160934\n",
      "epoch 6 time used: 0  seconds  train loss: 0.4724905830290582 validation loss: 0.628715326388677\n",
      "epoch 7 time used: 0  seconds  train loss: 0.4525258036123382 validation loss: 0.529049813747406\n",
      "epoch 8 time used: 0  seconds  train loss: 0.4617776564425892 validation loss: 0.2515124132235845\n",
      "epoch 9 time used: 0  seconds  train loss: 0.34428588507903946 validation loss: 0.052761043111483254\n",
      "epoch 10 time used: 0  seconds  train loss: 0.35047377687361503 validation loss: 0.6874980827172598\n",
      "epoch 11 time used: 0  seconds  train loss: 0.2619938535822762 validation loss: 0.10902606944243114\n",
      "epoch 12 time used: 0  seconds  train loss: 0.2929383913675944 validation loss: 0.3584916839996974\n",
      "epoch 13 time used: 0  seconds  train loss: 0.19194312476449543 validation loss: 0.2713899165391922\n",
      "epoch 14 time used: 0  seconds  train loss: 0.31479213014245033 validation loss: 0.05092873672644297\n",
      "epoch 15 time used: 0  seconds  train loss: 0.46657919014493626 validation loss: 0.04944755136966705\n",
      "epoch 16 time used: 0  seconds  train loss: 0.24566007405519485 validation loss: 0.3487912217775981\n",
      "epoch 17 time used: 0  seconds  train loss: 0.35479817456669277 validation loss: 0.33821625014146167\n",
      "epoch 18 time used: 0  seconds  train loss: 0.240856463710467 validation loss: 0.3428096224864324\n",
      "epoch 19 time used: 0  seconds  train loss: 0.20499376662903362 validation loss: 0.31431342164675397\n",
      "epoch 20 time used: 0  seconds  train loss: 0.2196423759063085 validation loss: 0.14954879383246103\n",
      "epoch 21 time used: 0  seconds  train loss: 0.26355546671483254 validation loss: 0.3160829444726308\n",
      "epoch 22 time used: 0  seconds  train loss: 0.3807276089986165 validation loss: 0.10167800883452098\n",
      "epoch 23 time used: 0  seconds  train loss: 0.25870860492189723 validation loss: 0.06712444126605988\n",
      "epoch 24 time used: 0  seconds  train loss: 0.14041610600219834 validation loss: 0.24821768701076508\n",
      "epoch 25 time used: 0  seconds  train loss: 0.1855645403265953 validation loss: 0.11428003013134003\n",
      "epoch 26 time used: 0  seconds  train loss: 0.3191330006553067 validation loss: 0.4108942697445552\n",
      "epoch 27 time used: 0  seconds  train loss: 0.18971098255780008 validation loss: 0.1269353578488032\n",
      "epoch 28 time used: 0  seconds  train loss: 0.19358989099661508 validation loss: 0.2194035996993383\n",
      "epoch 29 time used: 0  seconds  train loss: 0.19755887612700462 validation loss: 0.04248817761739095\n",
      "epoch 30 time used: 0  seconds  train loss: 0.14549470899833572 validation loss: 0.20494193335374197\n",
      "epoch 31 time used: 0  seconds  train loss: 0.15766396870215735 validation loss: 0.1672882636388143\n",
      "epoch 32 time used: 0  seconds  train loss: 0.12276097387075424 validation loss: 0.04606347779432932\n",
      "epoch 33 time used: 0  seconds  train loss: 0.20435492859946358 validation loss: 0.264175683259964\n",
      "epoch 34 time used: 0  seconds  train loss: 0.15638077300455835 validation loss: 0.09028368691603343\n",
      "epoch 35 time used: 0  seconds  train loss: 0.17437666323449877 validation loss: 0.25682031611601513\n",
      "epoch 36 time used: 0  seconds  train loss: 0.2404214520421293 validation loss: 0.1314249982436498\n",
      "epoch 37 time used: 0  seconds  train loss: 0.2766389101743698 validation loss: 0.06109007696310679\n",
      "epoch 38 time used: 0  seconds  train loss: 0.18175403525431952 validation loss: 0.15027262270450592\n",
      "epoch 39 time used: 0  seconds  train loss: 0.18761476046509212 validation loss: 0.03685378531614939\n",
      "epoch 40 time used: 0  seconds  train loss: 0.12921218077341715 validation loss: 0.11315535008907318\n",
      "epoch 41 time used: 0  seconds  train loss: 0.12177873485618168 validation loss: 0.16620666285355887\n",
      "epoch 42 time used: 0  seconds  train loss: 0.12942361500528124 validation loss: 0.1328623741865158\n",
      "epoch 43 time used: 0  seconds  train loss: 0.13626444298360083 validation loss: 0.18288990358511606\n",
      "epoch 44 time used: 0  seconds  train loss: 0.10958422637648052 validation loss: 0.0750923107067744\n",
      "epoch 45 time used: 0  seconds  train loss: 0.2494573431710402 validation loss: 0.08588641385237376\n",
      "epoch 46 time used: 0  seconds  train loss: 0.1482104468676779 validation loss: 0.2242442270119985\n",
      "epoch 47 time used: 0  seconds  train loss: 0.0907261177069611 validation loss: 0.030129094918568928\n",
      "epoch 48 time used: 0  seconds  train loss: 0.11948245639602344 validation loss: 0.06712959706783295\n",
      "epoch 49 time used: 0  seconds  train loss: 0.10722539532515737 validation loss: 0.20269068082173666\n",
      "epoch 50 time used: 0  seconds  train loss: 0.2523749139573839 validation loss: 0.4305303792158763\n",
      "epoch 51 time used: 0  seconds  train loss: 0.19234024360775948 validation loss: 0.1580412636200587\n",
      "epoch 52 time used: 0  seconds  train loss: 0.10207753711276585 validation loss: 0.18469772239526114\n",
      "epoch 53 time used: 0  seconds  train loss: 0.08835434748066796 validation loss: 0.0229921688636144\n",
      "epoch 54 time used: 0  seconds  train loss: 0.16264806770616108 validation loss: 0.046944702665011086\n",
      "epoch 55 time used: 0  seconds  train loss: 0.32224225708180004 validation loss: 0.32652754088242847\n",
      "epoch 56 time used: 0  seconds  train loss: 0.22006476463543045 validation loss: 0.06707630058129628\n",
      "epoch 57 time used: 0  seconds  train loss: 0.264400653127167 validation loss: 0.12099052965641022\n",
      "epoch 58 time used: 0  seconds  train loss: 0.23750267012251747 validation loss: 0.5074581603209177\n",
      "epoch 59 time used: 0  seconds  train loss: 0.3091049997342957 validation loss: 0.3544680029153824\n",
      "epoch 60 time used: 0  seconds  train loss: 0.2046290710568428 validation loss: 0.19238665203253427\n",
      "epoch 61 time used: 0  seconds  train loss: 0.19561244795719782 validation loss: 0.2620769888162613\n",
      "epoch 62 time used: 0  seconds  train loss: 0.17458278189102808 validation loss: 0.2824879338343938\n",
      "epoch 63 time used: 0  seconds  train loss: 0.30127167370584274 validation loss: 0.20454936226209006\n",
      "epoch 64 time used: 0  seconds  train loss: 0.18698358908295631 validation loss: 0.1248858521382014\n",
      "epoch 65 time used: 0  seconds  train loss: 0.1541796719862355 validation loss: 0.11722432076931\n",
      "epoch 66 time used: 0  seconds  train loss: 0.15718954594598877 validation loss: 0.04890124499797821\n",
      "epoch 67 time used: 0  seconds  train loss: 0.26107188479767907 validation loss: 0.5903686732053757\n",
      "epoch 68 time used: 0  seconds  train loss: 0.42520424640840954 validation loss: 0.3903023600578308\n",
      "epoch 69 time used: 0  seconds  train loss: 0.28967030180825126 validation loss: 0.05985832711060842\n",
      "epoch 70 time used: 0  seconds  train loss: 0.18581581239899 validation loss: 0.1520467350880305\n",
      "epoch 71 time used: 0  seconds  train loss: 0.290823826359378 validation loss: 0.41871926188468933\n",
      "epoch 72 time used: 0  seconds  train loss: 0.11863940995600489 validation loss: 0.10646036763985951\n",
      "Early stopping at epoch: 73\n",
      "Model Training Ended ... Mon May 23 02:35:27 2022\n"
     ]
    }
   ],
   "source": [
    "model = Transformer().cuda(device=device)\n",
    "model_dict['changchun'] = model\n",
    "train(model,'changchun',changchun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing Started ... Mon May 23 02:35:27 2022\n",
      "1 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 10076.4394644648, 100.3814697266, 100.3814697266, 7.1091692441\n",
      "2 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 2010.5349576622, 44.8389892578, 44.8389892578, 3.0113491778\n",
      "3 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 60.0038595349, 7.7462158203, 7.7462158203, 0.5013731923\n",
      "4 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 1987.4486690164, 44.5808105469, 44.5808105469, 2.7621320041\n",
      "5 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 4394.0132361054, 66.2873535156, 66.2873535156, 4.0174153646\n",
      "6 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 5970.1088531166, 77.2664794922, 77.2664794922, 4.6156797785\n",
      "7 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 6641.0761016756, 81.4927978516, 81.4927978516, 4.8220590445\n",
      "8 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 6445.1183014512, 80.2814941406, 80.2814941406, 4.7252203732\n",
      "9 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 6063.4889960885, 77.8684082031, 77.8684082031, 4.5643850060\n",
      "10 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 5374.7405548245, 73.3126220703, 73.3126220703, 4.2872878404\n",
      "11 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 4666.5142673403, 68.3118896484, 68.3118896484, 3.9901804701\n",
      "12 step, shenzhen, Transformer, MSE, RMSE, MAE, MAPE, 4106.9760933518, 64.0856933594, 64.0856933594, 3.7389552718\n",
      "Average MAE Loss is 65.5378519694\n",
      "Model Testing Ended ... Mon May 23 02:35:28 2022\n"
     ]
    }
   ],
   "source": [
    "test_model(model_dict['shenzhen'],'shenzhen',shenzhen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing Started ... Mon May 23 02:35:28 2022\n",
      "1 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 22700460.2500000000, 4764.5000000000, 4764.5000000000, 10.7730746620\n",
      "2 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 22573411.4751586914, 4751.1484375000, 4751.1484375000, 10.4379551771\n",
      "3 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 72840.9494628906, 269.8906250000, 269.8906250000, 0.5291246790\n",
      "4 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 24880.1330566406, 157.7343750000, 157.7343750000, 0.3018435329\n",
      "5 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 74413.8726196289, 272.7890625000, 272.7890625000, 0.5142500141\n",
      "6 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 204409.9512329102, 452.1171875000, 452.1171875000, 0.8407572060\n",
      "7 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 58326.0234985352, 241.5078125000, 241.5078125000, 0.4468312318\n",
      "8 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 12573.7676391602, 112.1328125000, 112.1328125000, 0.2064604737\n",
      "9 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 5066.5479125977, 71.1796875000, 71.1796875000, 0.1304254466\n",
      "10 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 2073.8062133789, 45.5390625000, 45.5390625000, 0.0830701614\n",
      "11 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 8278.1564941406, 90.9843750000, 90.9843750000, 0.1652068618\n",
      "12 step, shanghai, Transformer, MSE, RMSE, MAE, MAPE, 19823.7600097656, 140.7968750000, 140.7968750000, 0.2546516097\n",
      "Average MAE Loss is 947.5266927083\n",
      "Model Testing Ended ... Mon May 23 02:35:28 2022\n"
     ]
    }
   ],
   "source": [
    "test_model(model_dict['shanghai'],'shanghai',shanghai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing Started ... Mon May 23 02:35:28 2022\n",
      "1 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 677.5910229422, 26.0305786133, 26.0305786133, 3.7562162501\n",
      "2 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 82.1123131551, 9.0615844727, 9.0615844727, 1.2002098639\n",
      "3 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 161.3073637486, 12.7006835938, 12.7006835938, 1.6282927684\n",
      "4 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 874.4575270452, 29.5712280273, 29.5712280273, 3.6283715371\n",
      "5 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 3119.4447585978, 55.8519897461, 55.8519897461, 6.5095559145\n",
      "6 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 5105.4967385679, 71.4527587891, 71.4527587891, 8.0283998639\n",
      "7 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 7439.8942798413, 86.2548217773, 86.2548217773, 9.3450511135\n",
      "8 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 11107.1709728278, 105.3905639648, 105.3905639648, 10.9553600795\n",
      "9 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 15519.1617708802, 124.5759277344, 124.5759277344, 12.3956146999\n",
      "10 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 22558.6318969727, 150.1953125000, 150.1953125000, 14.2095849101\n",
      "11 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 29200.8313094117, 170.8825073242, 170.8825073242, 15.4365408604\n",
      "12 step, beijing, Transformer, MSE, RMSE, MAE, MAPE, 35460.5402453095, 188.3096923828, 188.3096923828, 16.2616314666\n",
      "Average MAE Loss is 85.8564707438\n",
      "Model Testing Ended ... Mon May 23 02:35:28 2022\n"
     ]
    }
   ],
   "source": [
    "test_model(model_dict['beijing'],'beijing',beijing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing Started ... Mon May 23 02:35:28 2022\n",
      "1 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 229892.1551551819, 479.4707031250, 479.4707031250, 2.0893790445\n",
      "2 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 207711.6230621338, 455.7539062500, 455.7539062500, 1.9790434072\n",
      "3 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 118985.9211769104, 344.9433593750, 344.9433593750, 1.4866966614\n",
      "4 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 18395.2002105713, 135.6289062500, 135.6289062500, 0.5774637299\n",
      "5 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 8843.7126197815, 94.0410156250, 94.0410156250, 0.3980572090\n",
      "6 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 2237.5486793518, 47.3027343750, 47.3027343750, 0.1989014144\n",
      "7 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 386.4449501038, 19.6582031250, 19.6582031250, 0.0822278125\n",
      "8 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 2289.5851173401, 47.8496093750, 47.8496093750, 0.1989506024\n",
      "9 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 4582.1264801025, 67.6914062500, 67.6914062500, 0.2805861399\n",
      "10 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 23469.4021949768, 153.1972656250, 153.1972656250, 0.6317413015\n",
      "11 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 44186.1748695374, 210.2050781250, 210.2050781250, 0.8636908461\n",
      "12 step, changchun, Transformer, MSE, RMSE, MAE, MAPE, 55903.6149940491, 236.4394531250, 236.4394531250, 0.9693717073\n",
      "Average MAE Loss is 191.0151367188\n",
      "Model Testing Ended ... Mon May 23 02:35:28 2022\n"
     ]
    }
   ],
   "source": [
    "test_model(model_dict['changchun'],'changchun',changchun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_day(model, name,days):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = days[:,0].reshape(1, -1).float()\n",
    "        y = days[:,1].reshape(1, -1).float()\n",
    "        attention_mask = torch.from_numpy(np.zeros((TIMESTEP, TIMESTEP)))\n",
    "        y_pred = model(x.cuda(), y.cuda(), attention_mask.cuda())[0][0][0]\n",
    "        # Does not output values that defy common sense.\n",
    "        if y_pred < y[0,-1]:\n",
    "            y_pred = y[0,-1]\n",
    "        return scaler_dict[name].inverse_transform(y_pred.cpu().reshape(-1,1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512.3815044144976"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_day(model_dict['shenzhen'],'shenzhen',shenzhen[18:18+TIMESTEP])\n",
    "predict_one_city = {} # 这个用来存储每个城市的预测数据, 对于每个城市都预测第31天到第42天的情况\n",
    "predict_one_city['shenzhen'] = []\n",
    "predict_one_city['changchun'] =[]\n",
    "predict_one_city['shanghai'] = []\n",
    "predict_one_city['beijing'] = []\n",
    "for i in range(0,12): \n",
    "    predict_one_city['shenzhen'].append(predict_day(model_dict['shenzhen'],'shenzhen',shenzhen[18+i:30+i]))\n",
    "for i in range(0,12): \n",
    "    predict_one_city['changchun'].append(predict_day(model_dict['changchun'],'changchun',changchun[18+i:30+i]))\n",
    "for i in range(0,12): \n",
    "    predict_one_city['shanghai'].append(predict_day(model_dict['shanghai'],'shanghai',shanghai[18+i:30+i]))\n",
    "for i in range(0,12):\n",
    "    predict_one_city['beijing'].append(predict_day(model_dict['beijing'],'beijing',beijing[18+i:30+i]))\n",
    "predict_one_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predict_another_city = {} # 这个预测使用不同城市的模型来体现不同城市的防疫效果\n",
    "predict_another_city['sz_to_sh'] = []  #这个时候预测第13到第42天情况\n",
    "predict_another_city['sh_to_sz'] = []\n",
    "predict_another_city['sz_to_cc'] = []\n",
    "predict_another_city['sz_to_bj'] = []\n",
    "# 使用深圳的模型来预测上海\n",
    "for i in range(0,30): \n",
    "    predict_another_city['sz_to_sh'].append(predict_day(model_dict['shenzhen'],'shenzhen',shanghai[0+i:12+i]))\n",
    "# 使用上海的模型来预测深圳\n",
    "for i in range(0,30): \n",
    "    predict_another_city['sh_to_sz'].append(predict_day(model_dict['shanghai'],'shanghai',shenzhen[0+i:12+i]))\n",
    "# 使用深圳的模型来预测长春\n",
    "for i in range(0,30): \n",
    "    predict_another_city['sz_to_cc'].append(predict_day(model_dict['shenzhen'],'shenzhen',changchun[0+i:12+i]))\n",
    "# 使用深圳的模型来预测北京\n",
    "for i in range(0,30): \n",
    "    predict_another_city['sz_to_bj'].append(predict_day(model_dict['shenzhen'],'shenzhen',beijing[0+i:12+i]))   \n",
    "predict_another_city"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
